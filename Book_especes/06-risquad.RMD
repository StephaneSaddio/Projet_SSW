---
output:
  html_document: default
  pdf_document: default
---

### Risque quadratique des estimateurs à noyau sur les classe des espaces de Hölder
   
  Nous nous intéressons au risque quadratique de $\hat{f}_n$, définit par :   
étant donné $x_0 \in \mathbb{R}$ 
$$
R(\hat {f}_n, f) = \mathbb{E}[|\hat {f}_n(x_0) - f(x_0)|^2]
$$

 Rappelons la décomposition "biais-variance" du risque quadratique :
$$
\mathbb{E}[|\hat {f}_n(x_0) - f(x_0)|^2] = (\mathbb{E}[\hat {f}_n(x_0)] - f(x_0))^2 + \mathbb{V}[\hat {f}_n(x_0)]
$$

  
#### Majoration du biais et de la variance

  Dans cette section, nous allons nous intéresser au compromis biais-variance afin de minimiser le risque quadratique.
Nous introduirons après quelques définitions deux propositions qui montrent que sous certaines hypothèses, on peut majorer le biais ainsi que la variance.\newline

\begin{dfn} Pour tout $\beta > 0$ et $L > 0$, on définit la classe de Hölder de régularité $\beta$ et de rayon $L$ par

$$
  \Sigma(\beta,L)={\{f:\mathbb{R} \longrightarrow \mathbb{R}\ \text{t.q.}\ f\ \text{est} \left\lfloor{\beta}\right\rfloor\ \text{fois dérivable et}   \\
  \forall\ (x,y) \in \mathbb{R}_2\ \ \mid f^{\left\lfloor{\beta}\right\rfloor}(y)-f^{\left\lfloor{\beta}\right\rfloor}(x)\mid \leq L{\mid x-y\mid}^{\beta - \left\lfloor{\beta}\right\rfloor}\}}
$$

On notera $\Sigma_d(\beta,L)$ l'intersection de $\Sigma(\beta,L)$ et l'ensemble des densités.

\end{dfn}
\begin{rem} 
- Si $\beta = 1$ on obtient l'ensemble des fonctions L-lipschitziennes.\newline
- Si $\beta > 1$ alors $f'\in \Sigma(\beta-1,L)$.
\end{rem}
\begin{prop} (admise) Soit $\beta > 0$ et $L > 0$, il existe une constante $M(\beta, L)$ telle que

$$
\underset{f \in \Sigma_d(\beta,L)}{sup}{\parallel f \parallel}_{\infty}= \underset{x \in \mathbb{R}}{sup}\ \underset{f \in \Sigma_d(\beta,L)}{sup}f(x) \leq M(\beta,L)
$$
\end{prop}

\begin{dfn} Soit $\ell \in \mathbb{N^*}$. On dit que le noyau $K$ est d'ordre $\ell$ si $u^jK(u)$ est intégrable et 
$\int u^jK(u)du =  0,\   \ j = {1,...,\ell}$

\end{dfn}
\begin{prop}: Si $f \in \Sigma(\beta,L)$ avec $\beta > 0$ et $L > 0$ et si $K$ est un noyau d'ordre $\ell = \left\lfloor{\beta}\right\rfloor$ tel que $\int |{u}^{\beta}|\,.|{K(u)}|~du < \infty$ alors pour tout $x_0 \in \mathbb{R}$, et pour tout $h>0$ le biais peut être borné comme suit:

$$
|\mathbb{E}[\hat{f}_n(x_0)] - f(x_0)|\leqslant \frac{h^{\beta}L}{\ell!}\int|u|^{\beta}|K(u)|du
$$
\end{prop}
  
\begin{demo} On a
$$
\begin{aligned}
\mathbb E\lgroup \hat f_n(x_0) \rgroup&=\mathbb E\lgroup\frac{1}{n}\sum_{i=1}^n \frac{1}{h}K(\frac{X_i-x_0}{h})\rgroup \\
&=\mathbb E\lgroup \frac{1}{h}K(\frac{X_1-x_0}{h})\rgroup \\
&=\frac{1}{h}\int K(\frac{u-x_0}{h})f(u)du  \\
&=\int K(v)f(x_0+hv)dv,\  (en\ posant\ v=\frac{u-x_0}{h}).
\end{aligned}
$$