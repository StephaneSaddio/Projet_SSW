[["méthodes-adaptatives.html", "Chapter 4 Méthodes adaptatives : 4.1 Choix du noyau 4.2 Choix de la fenêtre", " Chapter 4 Méthodes adaptatives : On introduit précédemment la notion de lestimation de la densité qui dépend dun paramètre de lissage h. Soit \\((\\hat{f_h})_{h\\in \\mathcal H}\\) une famille des estimateurs de le fonction densité \\(f\\) que que lon cherchons cherche à estimer. Une question simpose : comment peut on construire un estimateur à risque optimal à partir de cette famille en tenant en considération les observations ? Dans la théorie adaptative f est toujours supposée appartenir à une classe fonctionnelle. Cette classe nest pas connu à priori mais supposé appartenir à une famille de classes fonctionnelles{\\(\\mathcal{F_{\\alpha}},\\alpha \\in\\mathcal{A}\\)} où \\(\\mathcal{A}\\) est un ensemble des paramètres de nuisance. ( ref : Sur lestimation adaptative dune densité multivariée sous lhypothèse de la structure dindépendance-Approche minimax adaptative). Dans cette partie et afin de répondre a la question quon à posé auparavant, on va discuter en premier lieu du choix du noyau, ensuite on introduira deux méthodes pour le choix du paramètre de lissage h. 4.1 Choix du noyau Avant de présenter le critère de choix du noyau nous allons introduire quelques outils mathématiques qui simplifient lécriture du critère. Tout dabord, nous avons besoin du risque quadratique \\(\\mathcal R\\) aussi appelé lerreur quadratique moyenne (Mean Squared Error en anglais). Dans cette partie nous allons noté \\(MSE\\) le risque quadratique pour des questions pratiques. \\[ \\begin{aligned} MSE &amp;= \\mathcal R = \\mathbb E \\left[ \\{ \\hat f_n(x)-f(x) \\} \\right] \\\\ &amp;=\\mathbb V \\left[ \\hat f_n(x) \\right] + Biais^2 \\left[ \\hat f_n(x) \\right] \\\\ &amp;= MSE(x ; n, h, K, f). \\end{aligned} \\] comme nous lavons montré précédemment. @ref{#holder} Lapproximation de lerreur quadratique (Average of Mean Squared Error en anglais) est donnée par léquation suivante : \\[ AMSE(x)= \\frac1{nh} f(x) \\int_{\\mathbb R}K(t)^2 dt + \\left(\\frac12h^2f&#39;&#39;(x)\\int_{\\mathbb R} t^2K(t) dt \\right)^2. \\] Elle a été calculée à partir de la variance approchée et du biais approché. Lerreur quadratique moyenne intégrée (Mean Intregrated Squared Error en anglais) est une mesure théorique communément utilisée pour évaluer la différence entre \\(f\\) et \\(\\hat f_n\\). Pour lévaluer on utilise lerreur quadratique moyenne quon intègre sur le support \\(\\mathbb R\\) de lestimateur. \\[ \\begin{aligned} MISE(n,h,K,f) &amp;= \\int_{\\mathbb R}MSE(x;n,h,K,f)dx\\\\ &amp;= \\int_{\\mathbb R} \\mathbb V\\left[ \\hat f_n(x) \\right] dx+ \\int_{\\mathbb R} Biais^2 \\left[ \\hat f_n(x) \\right]dx \\end{aligned} \\] De la même façon que nous lavons fait avec lerreur quadratique moyenne, nous allons calculer lexpression approchée de lerreur quadratique moyenne (Average of Mean Integrated Squared Error en anglais). \\[ \\begin{aligned} AMISE(x)&amp;= \\frac1{nh} \\int_{\\mathbb R}f(x)dx \\int_{\\mathbb R}K(t)^2 dt + \\frac14h^4 \\int_{\\mathbb R}f&#39;&#39;(x)dx ~~\\left(\\int_{\\mathbb R} t^2K(t) dt \\right)^2\\\\ &amp;= \\frac1{nh} \\int_{\\mathbb R}K(t)^2 dt + \\frac14h^4 \\int_{\\mathbb R}f&#39;&#39;(x)dx ~~\\left(\\int_{\\mathbb R} t^2K(t) dt \\right)^2\\\\ &amp;= \\frac1{nh} \\int_{\\mathbb R}K(t)^2 dt + \\frac14h^4 ~ \\mathbb V (K)^2 \\int_{\\mathbb R}f&#39;&#39;(x)dx \\end{aligned} \\] à présent que nous avons défini les outils nécessaires au choix du noyaux, nous allons pouvoir présenter un critère de choix pour les noyaux continus symétriques. Afin de mesurer lefficacité des noyaux, nous utilisons une mesure qui calcule le rapport du critère \\(AMISE\\) de deux noyaux. \\[ eff(K_1,K_2) = \\frac{AMISE(K_1)}{AMISE(K_2)}. \\] Supposons que \\(K_1\\) est le noyau dEpanechnikov, il est souvent utilisé comme référence par rapport aux autres noyaux continus. Après quelques calculs, on obtient que lefficacité dun noyau K par rapport à celui dEpanachnikov est donnée par \\[ eff(K) = \\frac{3}{5\\times \\int_{\\mathbb R}K(t)^2 dt\\sqrt{5 \\times\\int_{\\mathbb R}t^2K(t) dt} } \\leq1. \\] Voici un tableau récapitulatif de lefficacité de plusieurs noyaux continus symétriques. dt &lt;- data.frame(Noyau = c(&quot;Epanechnikov&quot;, &quot;Bigweight&quot;, &quot;Triangular&quot;, &quot;Gaussien&quot;, &quot;Rectangulaire&quot;), Efficacité = c(1.000, 0.994, 0.986, 0.951, 0.930)) knitr::kable(dt, caption = &quot;Efficacité des noyaux continus symétriques&quot;) (#tab:ker_tab)Efficacité des noyaux continus symétriques Noyau Efficacité Epanechnikov 1.000 Bigweight 0.994 Triangular 0.986 Gaussien 0.951 Rectangulaire 0.930 ================== Noyau|Efficacité  Epanechnikov|1.000 Bigweight|0.994 Triangular|0.986 Gaussien|0.951 Rectangulaire|0.930 =================== 4.1.1 Comment choisir les paramètres de la méthode ? Dans la méthode destimation à noyau le choix du noyau nest pas le plus important, le vrai enjeu de cette méthode est le choix de la fenêtre \\(h\\) (bandwidth). En effet, la fenêtre détermine linfluence des données dans lestimation. Si \\(h\\) est petit, leffet local est important donc on aura beaucoup de bruit. Si \\(h\\) est grand on aura une estimation plus douce, plus lisse. Nous pouvons constater linfluence du paramètre \\(h\\) sur lexemple suivant : Nous avons simulé 500 variables suivant une loi de Weibull de paramètres (\\(\\alpha = 1.7\\), \\(\\lambda=2\\)) représentées dans lhistogramme. La courbe en rouge est la fonction de densité de la loi de Weibull et la bleue est lestimation avec la méthode des noyaux sur les variables simulées. La fenêtre \\(h\\) du second graphique est calculé automatiquement par la fonction densityde R. 4.2 Choix de la fenêtre 4.2.1 Choix de la fenêtre \\(h\\) par validation croisée 4.2.2 Méthode de Goldenshluger-Lepski 4.2.2.1 Inégalités doracle "]]
