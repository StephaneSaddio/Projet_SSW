---
title: "Méthodes non-paramétriques"
subtitle: Méthodes à noyau
author: 
- Wiam Chaoui
- Sophie Manuel
- Stéphane Sadio
date: "11/03/2021"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    extra_dependencies:
    - dsfont
  html_document:
    toc: yes
    df_print: paged
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

\newpage 
## Méthodes non-paramétriques

\newpage
## Estimation de densité par les estimateurs à noyau

  Notre but est d'estimer une densité $f$. Pour cela, on s’appuiera sur un échantillon iid $X= (X_1,...,X_n)$ où chacune des variables $X_i$ admet la densité $f$ (par rapport à la mesure de Lebesgue).

  Pour estimer une densité on peut utiliser une méthode à noyau.
  Les méthodes à noyau sont des méthodes non-paramétriques qui permettent de proposer une estimation de la densité plus lisse que celle obtenue par un histogramme.
  
### Comment construit-on un estimateur à noyau ?

L'idée pour la construction de cet estimateur est d'utiliser l'approximation suivante , valable lorsque h est petit :  
$$
f(x) = F'(x)\approx \frac{F(x+h)-F(x-h)}{2h}
$$
Pour estimer la densité $f$ on peut passer par un estimateur $\hat F_n$ de la fonction de répartion $F$. $\hat F_n$ est la fonction de répartition empirique ( $\hat F_n(x)= \frac1n \sum\limits_{i=1}^n\frac{1}{2h} \mathds1_{X_i \in ]x-h, x+h[}$ ).
$$
\hat f_n(x)= \frac{\hat F_n(x+h)-\hat F_n(x-h)}{2h} = \frac 1n \sum\limits_{i=1}^n \frac1{2h} \mathds1_{X_i \in ]x-h;x+h]}
$$

Notons $\hat f(x)$ l'estimateur à noyau de la densité $f$, alors celui-ci s'écrit :
$$
\hat f(x) = \frac1{nh} \sum\limits_{i=1}^n K\left(\frac{X_i-x}h\right)
$$
 où $h$ est la fenêtre (ou paramètre de lissage), $n$ le nombre d'observations, et $K$ le noyau.
 Cette formule n'est valable que si $h$ est petit et positif.
 
ici $K(u)= \frac12 \mathds{1}_{u \in ]-1;1]}$, il s'agit du noyau de Rosenblatt, mais il existe d'autres noyaux.

### Explication ce qu'est un noyau ?

**Définition :** Un noyau (*kernel* en anglais) est une application $K:\mathbb{R}\rightarrow\mathbb{R}$ intégrable et centrée telle que :
$$
\int_\mathbb R K(u) du = 1 ~~~~ \hbox{ et } ~~~~ \int_\mathbb R u K(u)=0
$$
si le noyau est en plus positif alors il correspond à une fonction de densité.

Exemples de noyau :

 - Noyau de Rosenblatt, ou rectangulaire : $K(u)= \frac12 \mathds{1}_{u\in]-1;1]}$
 
 - Noyau Gaussien : $K(u) =\frac1{\sqrt{2\pi}}exp(-\frac{u^2}2)$ 
 
 - Noyau d’Epanechnikov : $K(u) =\frac34(1-u^2)\mathds{1}_{[-1,1]}(u)$
 
 - Noyau triangulaire : $K(u) = (1-\mid u \mid)\mathds{1}_{[-1,1]}(u)$
 
 - Noyau Biweight : $K(u) = \frac{15}{16}(1-u^2)^2\mathds{1}_{[-1,1]}(u)$

Les propriétés du noyau (continuité, différentiabilité...) se transmettent à l'estimateur $\hat f_n$.

### Comment choisir les paramètres de la méthode ?

  Dans les méthodes à noyau le choix du noyau n'est pas le plus important, le vrai enjeu de cette méthode est le choix de la fenêtre $h$ (*bandwidth*).
  En effet, la fenêtre détermine l'influence des données dans l'estimation. Si $h$ est petit, l'effet local est important donc on aura beaucoup de bruit. Si $h$ est grand on aura une estimation plus douce, plus lisse.
  
  Nous pouvons constater l'influence du paramètre $h$ sur l'exemple suivant :
  Nous avons simulé 500 variables suivant une loi de Weibull de paramètres ($\alpha = 1.7$, $\lambda=2$) représentées dans l'histogramme. La courbe en rouge est la vraie fonction de densité et la bleue est l'estimation avec la méthode des noyaux sur les variables simulées.
```{r}
par(mfrow=c(1,3))

seq <- seq(0,6, length.out = 40)
yweib <- dweibull(seq,1.7,2)
rand <-rweibull(500,1.7,2)

hist(rand, breaks = 12, freq = F, main = "")
lines(density(rand, bw = 0.1), col ="blue")
lines(density(rand), col ="blue")
lines(density(rand, bw = 2), col ="blue")
lines(seq, yweib, col="red")
title("Fenêtre trop petite,\n h = 0.1")

hist(rand, breaks = 12, freq = F, main = "")
lines(density(rand), col ="blue")
lines(seq, yweib, col="red")
title("Fenêtre raisonnable,\n h = 0.372")

hist(rand, breaks = 12, freq = F, main = "")
lines(density(rand, bw = 2), col ="blue")
lines(seq, yweib, col="red")
title("Fenêtre trop petite,\n h = 2")


```
La fenêtre $h$ du second graphique est calculé automatiquement par la fonction `density`de R. 
  
### Comment choisir la fenêtre ?

  Afin d'expliquer comment choisir une fenêtre, nous devons définir quelques objets.
  - Notons $d$ la distance, nous préciserons laquelle si besoin.
  - Soit $\omega : \mathbb R \rightarrow \mathbb R^+$ telle que $\omega$ est convexe et $\omega(0)=0$ alors $\omega$ est la fonction de perte.
  - On appelle risque de l'estimateur $\hat f_n$ : 
  
$$\hat R(\hat f_n, f) = \mathbb E [ \omega(d(\hat f_n, f))]$$

Dans la suite on prendra le risque quadratique donc $\omega : x \rightarrow x^2$ et $d:(f,g) \rightarrow \sqrt{\int_{\mathbb R}(f(x)-g(x))^2dx }$ la distance dans $L^2$.

  On peut déterminer un $h$ optimal par validation croisée, avec la fonction de risque.
Puisque $h$ dépend de la régularité de la fonction qui est inconnue, nous allons estimer cette fenêtre optimale par un estimateur $\hat h$.
  Pour cela, on cherche à minimiser en $h$ le risque quadratique dans $L^2$.
  $$
  R(\hat f_{n,h},f)= \mathbb E[ \parallel \hat f_{n,h}-f \parallel_2^2 ]
  $$
  
  En pratique on ne peut pas calculer ce risque car il dépend de $f$ qui est inconnu, donc on utilisera un estimateur de ce risque. On remarquera que minimiser $R(\hat f_{n,h},f)$ en $h$ équivaut à minimiser $R(\hat f_{n,h},f)-\parallel f \parallel_2^2$ en $h$. On cherchera un estimateur (sans biais) de cette dernière.
On suppose aussi que $R(\hat f_{n,h},f)<\infty$ et que $f\in L^2$.
  Alors, d'après un théorème,
$$
  \hat R(h)=\parallel \hat f_{n,h}\parallel_2^2 - \frac2{n(n-1)} \sum\limits_{i=1}^n \sum\limits_{j=1,j \neq i}^n \frac1h K\left(\frac{X_i-X_j}h\right)
$$

est un estimateur sans biais de $R(\hat f_{n,h},f)-\parallel f \parallel_2^2$.

On en déduit donc que :
$$
\hat h = \arg\min\limits_{h>0}\hat R(h)
$$

Lorsque le minimum est atteint on obtient un $\hat h$ optimal.