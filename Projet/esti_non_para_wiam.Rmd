---
author: "Wiam Chaoui        Stéphane Sadio      Sophie Manuel   "
header-includes:
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhead[L]{Combient de temps pour crée une espèce ?}
  - \fancyhead[R]{\emph{M1 - Biostatistique}}
  - \usepackage{dsfont}
  - \usepackage{subfig}
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{amsthm}
  - \usepackage{amsmath}
output:
  pdf_document: 
    toc_depth: 6
    number_sections: yes
    extra_dependencies: dsfont
editor_options: 
  markdown: 
    wrap: 72
---

```{=tex}
\newtheorem{definition}{Définition}
\newtheorem{exemple}{Exemple}
\newtheorem{corollary}{Corollaire}
\newtheorem*{proposition}{Proposition}
\newtheorem{lemma}{Lemme}
\newtheorem*{demonstration}{Démonstration}
\newtheorem{remark}{Remarque}
\newtheorem{propetie}{Propriété}
\newpage
\tableofcontents
\newpage
```

------------------------------------------------------------------------

# Introduction génerale 

\fancyhead[R]{Introduction}

## Motivation

 \hspace*{1cm}
On a *une arbre phylogénétique* présentant les relations de parenté
entre *espèces* et on s'interesse au *branchement évolutif* apparaît
après une durée aleatoire d'une loi fixée $\mu$ indépendamment du passé
et du future évolutifs des espèces .\newline Quelle est cette loi $\mu$
? Sa variance ? Sa moyenne ?.\newline




## Problématique


 \hspace*{1cm}  On obsérve les successions de branchements qui composent un arbre
phylogénétique et a parir des ces données quantitatives obsérvées on
veut a éstimer la fonction $f$ qui donne le temps qu'il faut pour
qu'un branchement évolutif apparaisse .\newline    
  Formellement ; On a un
échantillon $\chi$={$X_1,...,X_n$} de variables obsérvés qui ont pour
fonction de densité $f$ dans $\mathcal F$ où $\mathcal F$ est un éspace
fonctionnel .On cherche a éstimer cette fontion densité $f$ sur la
quelle on fait le moins d'hypothéses possibles .D'où le modéle suivant
{$P={P_f,f\in \mathcal F}$} qui revient a faire une éstimation
non-paramétrique .\newline Pour répondre a la problématque on cherchera
a comprendre et finalement implémenter un éstimateur à noyau adaptif ,
de type Goldenshluger-Lepski sur des données d'arbres phylogénétiques
.\newpage

# Méthodes non-paramétriques

\fancyhead[R]{Méthodes non-paramétriques}

  \hspace*{1cm} En statistique ,on parle de l'éstimation quand cherche à trouvé certains paramétres inconus caractérisant une distribution a partir d'un échantillon de données observées en se basant sur differetes méthodes.
On se tourne vers l'estimataion non-paramétrique lorsqu'on traite des paramétres à dimension infini . c'e qui est'est bien notre cas, comme on cherche à éstimer une fonction densité qui apartien au espace fonctionnel .\newline 
 \hspace*{1cm} On présente dans la suite une courte introduction
de l'estimation non paramétrique .On introduit ensuite les deux classes
principales de l'estimation fonctionnelle (l'éstimation par projection
et l'éstimation à noyau) afin de discuter de ces
deux classes et de pourquoi on fait le choix de l'éstimation à noyau
.\newline

## Définitions


\begin{definition}
    Èstimation non-paramétrique:\newline
 L'éstimation non-paramétrique vise à résoudre des problémes d'éstmation dans le cadre statistique où le modéle dont on s'intéresse n'est pas décrit par un nombre fini de paramètres et dont chacun de ces paramétres ne permet pas de décrire la structure générale de la distribution des variables aléatoires.\newline Cela signifit qu'on utilise des modéles statistiques à dimension infinis .
\end{definition}


  Dans le cadre de notre problématique on s'interesse a l'estimation de
densité .\newline

\begin{definition}
Èstimation à densité:\newline
  Un des proncipes de base de l'éstimation à densité selon une méthode d'éstimation non-paramétrique est le suivant :\newline
Pour un échantillon des obsérvations quantitatives $\mathbb {X}$ ={$X_1.....,X_n$} des variables aléatoires i.i.d admettant une densité $f= F'$ . Supposons que $f \in \mathcal F$ où
$\mathcal{F}$un espace fonctionnel on cherche a éstimer la fonction
inconnu $f$ à partir de ces observations.\newline On notera $\hat f n$ l'estimateur de f.\newline
On se trouve donc avec le modéle suivant {$\mathbb P$ }{ 
$\mathbb P_f ,f \in \mathcal F$ }, tel que $\mathbb P_f$ est la
mesure probabilté de la densité $f$ .
\end{definition}

  L'éstimation ici concerne donc la fonction elle même plutôt que les paramétres ,ce qui éxplique le nom de l'éstimation non-paramétrique .\newline


\begin{remark} 
-On notera dans la suite $\hat f$ l'éstimateur de la vrai fonction
$f$.\newline
-On prend souvent les distance $L^p$ avec p =1,2 ou $\infty$ .
\end{remark}


Ils éxiste deux grandes familles de méthodes pour éstimer une fonction densité  :\newline
   \hspace*{1cm}  Èstimation par projection .\newline
   \hspace*{1cm}  Èstimation par le noyau .

## Èstimateurs par projéction :


\begin{definition}
Èstimation par projection:\newline
Supposant que la fonction $f$ à éstimer est dans l'éspace de Hilbert
$\mathcal F = (L^2 , ||.||, <.,.>)$ avec $(\Phi_j)_{j>0}$ une base orthonormée de $L^2$ ,$\mathbb E _N$  un sous-espace fini de $\mathcal F$ et $1 \leq |N| < \infty$.\newline
De plus $a_{\lambda} = <f,\Phi_{\lambda}> = \int_{\mathbb R}f(x)\Phi_{\lambda}(x) dx$.\newline
Alors, on éstime la fonction $f$ par son projeté 

$$
\Pi_Nf = \sum_{\lambda \in N} a_{\lambda} \Phi_{\lambda}
$$
\end{definition}



\begin{remark}
-Cette méthode nous raméne au cas paramétrique .\newline
-Plus la valeur de N est grande plus le biais est petit et la variance est grande .
\end{remark}



 Dans la suite on procedra avec la méthode la plus fréquente utilisée pour l'éstimation d'une densité : L'éstimation par le noyau.\newline 

# Èstimateur de densité à noyau :

\fancyhead[R]{Èstimateur de densité à noyau}

## Èvaluer un éstimateur 

Pour évaluer un éstimateur on définit le risque associé d'un éstimateur $\hat f$ pour l'éstimateur f.\newline

\begin{definition} 
La fonction de risque : 
$$ 
\mathcal R(\hat f ,f)=\mathbb E_f[||\hat f -f||^2]
$$
\end{definition}


\begin{remark}
  La fonction de risque associé nous permet de comparer l'éstimateur $\hat f$ et l'éstimation f .\newline
On cherche a ce que ce risque associé soit minimal (i.e tend vers 0 pour un nombre d'obsérvation assez grand.)\newline
\end{remark}

\begin{proposition}

Dans le cas d'un éstimateur à noyau , on a :\newline
$$
R(\hat{f},f)=E_f[||\hat{f}-f||^2 ] = ||f-K_h*f ||^2 + E_f[||\hat{f}-K_h*f ||^2]
$$
\end{proposition}

\begin{demonstration}
On que :\newline 


$E_f||\hat{f}-f ||^2 = \mathbb {E}_f[||\hat{f}+\mathbb {E}_f(\hat{f} )-(\mathbb {E}_f(\hat{f} )-f)|| ]^2$.\newline

$E_f||\hat{f}-f ||]^2 = \mathbb {E}_f||\hat{f}+E_f(\hat{f} )||^2 +\mathbb {E}_f||\mathbb {E}_f(\hat{f} )-f|| ^2 - 2 \mathbb {E}_f(<\hat{f}-\mathbb {E}_f(\hat{f});\mathbb {E}_f(\hat{f})-f>)$.\newline

Comme $\hat{f}$ est déterministe\newline 
$2\mathbb {E}_f(<\hat{f}-E_f(\hat{f});\mathbb {E}_f(\hat{f})-f>)=2<0,E_f(\hat{f})-f>=0$\newline
Ainsi $||\mathbb {E}_f(\hat{f} )-f||$ est déterministe\newline
On obtient :\newline
$R(\hat{f},f)=\mathbb {E}_f[||\hat{f}-f||^2 ] = ||f-K_h*f ||^2 + \mathbb {E}_f[||\hat{f}-K_h*f||^2]$ 
\end{demonstration}

On à bien trouver que\newline
$R(\hat{f},f)=biais^2+\mathbb Var$\newline

\begin{remark}\
   Plus la  valeur de h est  grande,plus le biais devient  grand et la variance petite et vis-vers-ca ; plus la valeur de h est petite plus le  biais devient petit et la variance s'explose.\newline
\end{remark}
 
Donc afin de minimiser l'éxpression de risque le choix  de h est trés influent et même plus crucial pour la qualité de l'éstimateur que celui de la noyau $K$ .\newline
On doit chercher le meilleur compromis biais-variance pour afin avoir un risque minimal.\newline
Un paramétre trop faible provoque l'apparition de détails artificiels sur le graph de l'éstimateur(La variance devient trop grande), par contre si on prend une valeur de h très grande on aura la majorité des caractéristiques éffacée .\newline


[![](C:\Users\wiam chaoui\Documents\Projet pfe\Bias-variance-trade-off){width="310"}](http://chimix.com/an16/pol16/image/aspts35.jpg)


## Méthodes adabtatives :

 \hspace*{1cm} On a introduit précedement la notion de l'éstimation de densité qui dépend d'un paramétre de lissage h. Soit  $(\hat{f_h})_{h\in \mathcal H}$ une famille des éstimateurs de la vrai fonction densité $f$ .\newline
 La question qui se pose   est donc la suiva,te  : comment peut on construire un éstimateur à risque optimal à partir de cette famille (en prenant en considération les obsérvations) ? \newline
  \hspace*{1cm}  Dans cette partie et afin de repondre a la question qu'on a poser on va discuter au premier temps du choix du noyau . Ensuite, on va introduir deux méthodes pour le choix du paramétre de lissage h .
 
### Choix du noyau 
On note par le noyau la fonction intégrable K : $\mathbb R \rightarrow \mathbb R$  tel que , $\int_{\mathbb R} K(u) du = 1$.\newline
Soient :\newline
h>0 le paramétre de lissage .\newline
$K_h : u \in \mathbb R \rightarrow K(\frac{u}{h})/h$.\newline

\begin{lemma}
On peut approximer la famille $(K_h)_{h>0}$ par l'identité du produit de convolution .
\end{lemma}

\begin{demonstration}
A Faire
\end{demonstration}

\begin{corollary}
$K_h * f : x \rightarrow \int_{\mathbb R} K_h(y-x) f(x) dx$ tend vers la fonction f quand h tend vers 0 .(pour la distance $L^2$)
\end{corollary}

### Choix de la fenêtre 
  L'éstimation de densité nécessite le choix de la fentêtre qu'on note h .\newline En statistique non-paramétrique , ils éxistent plusieurs méthodes et critéres de qualité pour le choix de la fêntere .\newline
  
  On présente dans la suite deux méthodes :\newline
   \hspace*{1cm}  Méthode de validation croisée .\newline
   \hspace*{1cm} Méthode de Goldenshluger-Lepski .\newline
    
#### Méthode par validation croisée 

#### Méthode de  Goldenshluger-Lepski 


  La méthode de Lepski donne principalement des critéres pour le choix entre éstimateurs à noyau $(\hat{f_h})_{h\in \mathcal H}$ avec différentes fenêtres qu'on fixe en prennat on considération l'échantillon des obsérvations.\newline
  Cette méthode propose de choisir le $\hat h$ qui minimise l'éxpression suivante :
$$
B(h)+V(h)
$$
Avec :

$$
B(h)=sup_{h' \in \mathcal H}{[||\hat f_{h'} - \hat f _h ||-V(h')]}
$$
Et 
$$
V(h)=a \frac{||K_{h'}||^2}{n}
$$
Tel que K est le noyau ,$a$ un paramétre et V(h) est le terme de pénalisation .\newline

On a donc le $\hat h$ est égale à  :
$$
\hat h = arg min_{h \in \mathcal H}(B(h)+V(h))
$$
\begin{remark}
Le terme de pénalisation choisi est proportionne a la variance de l'éstimateur .
\end{remark}


  On s'interesse dans cette méthode à déterminer le terme de pénalisation minimal V(h) tel que si on le dépasse on n'obtient plus l'équilibre biais-variance .\newline
  
  Dans ce cas , la valeur de $\hat h$ est d'ordre $\frac{1}{n}$ ,
  
  Le choix optimal de la fenétre h suivant cette méthode dans ce cas est $n^{-\frac{1}{2 \alpha +1}}$